{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "%matplotlib notebook\n",
    "from argparse import ArgumentParser\n",
    "import yaml\n",
    "import os\n",
    "import torch\n",
    "# from torch import vmap\n",
    "from functorch import vmap, grad\n",
    "\n",
    "from models import FNN2d, FNN2d_AD\n",
    "from train_utils import Adam\n",
    "# from train_utils.datasets import BurgersLoader'\n",
    "# from train_utils.train_2d import train_2d_burger\n",
    "# from train_utils.eval_2d import eval_burgers\n",
    "\n",
    "from solver.BurgersEq import BurgersEq1D\n",
    "import traceback\n",
    "\n",
    "import scipy.io\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import imageio\n",
    "\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "from train_utils.utils import get_grid, save_checkpoint, torch2dgrid, load_checkpoint, load_config, update_config\n",
    "from train_utils.losses import LpLoss\n",
    "from train_utils.datasets import DataLoader1D\n",
    "# from utils import torch2dgrid\n",
    "from solver.my_random_fields import GRF_Mattern\n",
    "\n",
    "from importlib import reload\n",
    "\n",
    "try:\n",
    "    import wandb\n",
    "except ImportError:\n",
    "    wandb = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Loss Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spectral Derivatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FDM_Burgers(u, D=1, nu=0.01):\n",
    "    batchsize = u.size(0)\n",
    "    nt = u.size(1)\n",
    "    nx = u.size(2)\n",
    "\n",
    "    u = u.reshape(batchsize, nt, nx)\n",
    "    u2 = u**2\n",
    "    dt = D / (nt-1)\n",
    "    dx = D / (nx)\n",
    "\n",
    "    u_h = torch.fft.fft(u, dim=2)\n",
    "    u2_h = torch.fft.fft(u2, dim=2)\n",
    "    # Wavenumbers in y-direction\n",
    "    k_max = nx//2\n",
    "    k_x = torch.cat((torch.arange(start=0, end=k_max, step=1, device=u.device),\n",
    "                     torch.arange(start=-k_max, end=0, step=1, device=u.device)), 0).reshape(1,1,nx)\n",
    "    ux_h = 2j *np.pi*k_x*u_h\n",
    "    u2x_h = 2j *np.pi*k_x*u2_h\n",
    "    uxx_h = 2j *np.pi*k_x*ux_h\n",
    "    ux = torch.fft.irfft(ux_h[:, :, :k_max+1], dim=2, n=nx)\n",
    "    u2x = torch.fft.irfft(u2x_h[:, :, :k_max+1], dim=2, n=nx)\n",
    "    uxx = torch.fft.irfft(uxx_h[:, :, :k_max+1], dim=2, n=nx)\n",
    "    ut = (u[:, 2:, :] - u[:, :-2, :]) / (2 * dt)\n",
    "    Du = ut + (0.5*u2x - nu*uxx)[:,1:-1,:]\n",
    "#     Du = ut + (u*ux - nu*uxx)[:,1:-1,:]\n",
    "    return Du\n",
    "\n",
    "def PINO_loss_Burgers(u, u0, nu=0.01):\n",
    "    batchsize = u.size(0)\n",
    "    nt = u.size(1)\n",
    "    nx = u.size(2)\n",
    "\n",
    "    u = u.reshape(batchsize, nt, nx)\n",
    "    # lploss = LpLoss(size_average=True)\n",
    "\n",
    "    index_t = torch.zeros(nx,).long()\n",
    "    index_x = torch.tensor(range(nx)).long()\n",
    "    boundary_u = u[:, index_t, index_x]\n",
    "    loss_u = F.mse_loss(boundary_u, u0)\n",
    "\n",
    "    Du = FDM_Burgers(u, nu=nu)[:, :, :]\n",
    "    f = torch.zeros(Du.shape, device=u.device)\n",
    "    loss_f = F.mse_loss(Du, f)\n",
    "\n",
    "    # loss_bc0 = F.mse_loss(u[:, :, 0], u[:, :, -1])\n",
    "    # loss_bc1 = F.mse_loss((u[:, :, 1] - u[:, :, -1]) /\n",
    "    #                       (2/(nx)), (u[:, :, 0] - u[:, :, -2])/(2/(nx)))\n",
    "    return loss_u, loss_f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_Burgers(model,\n",
    "                  train_loader,\n",
    "                  optimizer, \n",
    "                  scheduler,\n",
    "                  config,\n",
    "                  rank=0,\n",
    "                  log=False,\n",
    "                  project='PINO-2d-default',\n",
    "                  group='default',\n",
    "                  tags=['default'],\n",
    "                  use_tqdm=True):\n",
    "    if rank == 0 and wandb and log:\n",
    "        run = wandb.init(project=project,\n",
    "                         entity='shawngr2',\n",
    "                         group=group,\n",
    "                         config=config,\n",
    "                         tags=tags, reinit=True,\n",
    "                         settings=wandb.Settings(start_method=\"fork\"))\n",
    "\n",
    "    data_weight = config['train']['xy_loss']\n",
    "    f_weight = config['train']['f_loss']\n",
    "    ic_weight = config['train']['ic_loss']\n",
    "    nu = config['data']['nu']\n",
    "    ckpt_freq = config['train']['ckpt_freq']\n",
    "\n",
    "    model.train()\n",
    "    myloss = LpLoss(size_average=True)\n",
    "    \n",
    "    pbar = range(config['train']['epochs'])\n",
    "    if use_tqdm:\n",
    "        pbar = tqdm(pbar, dynamic_ncols=True, smoothing=0.1)\n",
    "\n",
    "    for e in pbar:\n",
    "        model.train()\n",
    "        train_pino = 0.0\n",
    "        data_l2 = 0.0\n",
    "        train_loss = 0.0\n",
    "\n",
    "        for x, y in train_loader:\n",
    "            x, y = x.to(rank), y.to(rank)\n",
    "            out = model(x).reshape(y.shape)\n",
    "            data_loss = myloss(out, y)\n",
    "            \n",
    "            loss_u, loss_f = PINO_loss_Burgers(out, x[:, 0, :, 0], nu=nu)\n",
    "            total_loss = loss_u * ic_weight + loss_f * f_weight + data_loss * data_weight\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            total_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            data_l2 += data_loss.item()\n",
    "            train_pino += loss_f.item()\n",
    "            train_loss += total_loss.item()\n",
    "        scheduler.step()\n",
    "        data_l2 /= len(train_loader)\n",
    "        train_pino /= len(train_loader)\n",
    "        train_loss /= len(train_loader)\n",
    "        if use_tqdm:\n",
    "            pbar.set_description(\n",
    "                (\n",
    "                    f'Epoch {e}, train loss: {train_loss:.5f} '\n",
    "                    f'train f error: {train_pino:.5f}; '\n",
    "                    f'data l2 error: {data_l2:.5f}'\n",
    "                )\n",
    "            )\n",
    "        if wandb and log:\n",
    "            wandb.log(\n",
    "                {\n",
    "                    'Train f error': train_pino,\n",
    "                    'Train L2 error': data_l2,\n",
    "                    'Train loss': train_loss,\n",
    "                }\n",
    "            )\n",
    "\n",
    "        if e % ckpt_freq == 0:\n",
    "            save_checkpoint(config['train']['save_dir'],\n",
    "                            config['train']['save_name'].replace('.pt', f'_{e}.pt'),\n",
    "                            model, optimizer)\n",
    "    save_checkpoint(config['train']['save_dir'],\n",
    "                    config['train']['save_name'],\n",
    "                    model, optimizer)\n",
    "    print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_Burgers_padding(model,\n",
    "                          train_loader,\n",
    "                          optimizer, \n",
    "                          scheduler,\n",
    "                          config,\n",
    "                          padding=0,\n",
    "                          rank=0,\n",
    "                          log=False,\n",
    "                          project='PINO-2d-default',\n",
    "                          group='default',\n",
    "                          tags=['default'],\n",
    "                          use_tqdm=True):\n",
    "    \n",
    "    if rank == 0 and wandb and log:\n",
    "        run = wandb.init(project=project,\n",
    "                         entity='shawngr2',\n",
    "                         group=group,\n",
    "                         config=config,\n",
    "                         tags=tags, reinit=True,\n",
    "                         settings=wandb.Settings(start_method=\"fork\"))\n",
    "\n",
    "    data_weight = config['train']['xy_loss']\n",
    "    f_weight = config['train']['f_loss']\n",
    "    ic_weight = config['train']['ic_loss']\n",
    "    nu = config['data']['nu']\n",
    "    ckpt_freq = config['train']['ckpt_freq']\n",
    "    model.train()\n",
    "    myloss = LpLoss(size_average=True)\n",
    "    \n",
    "    pbar = range(config['train']['epochs'])\n",
    "    if use_tqdm:\n",
    "        pbar = tqdm(pbar, dynamic_ncols=True, smoothing=0.1)\n",
    "\n",
    "    for e in pbar:\n",
    "        model.train()\n",
    "        train_pino = 0.0\n",
    "        data_l2 = 0.0\n",
    "        train_loss = 0.0\n",
    "\n",
    "        for x, y in train_loader:\n",
    "            x, y = x.to(rank), y.to(rank)\n",
    "#             print(y.shape)\n",
    "            x_in = F.pad(x, (0, 0, 0, 0, 0, padding), \"constant\", 0)\n",
    "#             display(x.shape, x_in.shape)\n",
    "            batch_size, T, S = old_shape = y.shape\n",
    "            new_shape = (batch_size, T + padding, S)\n",
    "            out = model(x_in).reshape(batch_size, T + padding, S)\n",
    "            out = out[..., :-padding, :]\n",
    "            \n",
    "#             out = model(x).reshape(y.shape)\n",
    "            u0 = x[:, 0, :, 0]\n",
    "    \n",
    "            data_loss = myloss(out.view(batch_size, T, S), y.view(batch_size, T, S))\n",
    "            \n",
    "            loss_u, loss_f = PINO_loss_Burgers(out.view(batch_size, T, S), u0, nu=nu)\n",
    "            total_loss = loss_u * ic_weight + loss_f * f_weight + data_loss * data_weight\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            total_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            data_l2 += data_loss.item()\n",
    "            train_pino += loss_f.item()\n",
    "            train_loss += total_loss.item()\n",
    "        scheduler.step()\n",
    "        data_l2 /= len(train_loader)\n",
    "        train_pino /= len(train_loader)\n",
    "        train_loss /= len(train_loader)\n",
    "        if use_tqdm:\n",
    "            pbar.set_description(\n",
    "                (\n",
    "                    f'Epoch {e}, train loss: {train_loss:.5f} '\n",
    "                    f'train f error: {train_pino:.5f}; '\n",
    "                    f'data l2 error: {data_l2:.5f}'\n",
    "                )\n",
    "            )\n",
    "        if wandb and log:\n",
    "            wandb.log(\n",
    "                {\n",
    "                    'Train f error': train_pino,\n",
    "                    'Train L2 error': data_l2,\n",
    "                    'Train loss': train_loss,\n",
    "                }\n",
    "            )\n",
    "\n",
    "        if e % ckpt_freq == 0:\n",
    "            save_checkpoint(config['train']['save_dir'],\n",
    "                            config['train']['save_name'].replace('.pt', f'_{e}.pt'),\n",
    "                            model, optimizer)\n",
    "    save_checkpoint(config['train']['save_dir'],\n",
    "                    config['train']['save_name'],\n",
    "                    model, optimizer)\n",
    "    print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_Burgers(model,\n",
    "                 dataloader,\n",
    "                 config,\n",
    "                 device,\n",
    "                 use_tqdm=True):\n",
    "    model.eval()\n",
    "    myloss = LpLoss(size_average=True)\n",
    "    nu = config['data']['nu']\n",
    "    if use_tqdm:\n",
    "        pbar = tqdm(dataloader, dynamic_ncols=True, smoothing=0.05)\n",
    "    else:\n",
    "        pbar = dataloader\n",
    "\n",
    "    test_err = []\n",
    "    f_err = []\n",
    "    with torch.no_grad():\n",
    "        for x, y in pbar:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            out = model(x).reshape(y.shape)\n",
    "            data_loss = myloss(out, y)\n",
    "\n",
    "            loss_u, f_loss = PINO_loss_Burgers(out, x[:, 0, :, 0], nu=nu)\n",
    "            test_err.append(data_loss.item())\n",
    "            f_err.append(f_loss.item())\n",
    "\n",
    "    mean_f_err = np.mean(f_err)\n",
    "    std_f_err = np.std(f_err, ddof=1) / np.sqrt(len(f_err))\n",
    "\n",
    "    mean_err = np.mean(test_err)\n",
    "    std_err = np.std(test_err, ddof=1) / np.sqrt(len(test_err))\n",
    "\n",
    "    print(f'==Averaged relative L2 error mean: {mean_err}, std error: {std_err}==\\n'\n",
    "          f'==Averaged equation error mean: {mean_f_err}, std error: {std_f_err}==')\n",
    "\n",
    "\n",
    "def eval_Burgers_padding(model,\n",
    "                         dataloader,\n",
    "                         config,\n",
    "                         padding=0,\n",
    "                         device=None,\n",
    "                         use_tqdm=True):\n",
    "    model.eval()\n",
    "    myloss = LpLoss(size_average=True)\n",
    "    nu = config['data']['nu']\n",
    "    if use_tqdm:\n",
    "        pbar = tqdm(dataloader, dynamic_ncols=True, smoothing=0.05)\n",
    "    else:\n",
    "        pbar = dataloader\n",
    "\n",
    "    test_err = []\n",
    "    f_err = []\n",
    "    with torch.no_grad():\n",
    "        for x, y in pbar:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            x_in = F.pad(x, (0, 0, 0, 0, 0, padding), \"constant\", 0)\n",
    "            batch_size, T, S = old_shape = y.shape\n",
    "            new_shape = (batch_size, T + padding, S)\n",
    "            out = model(x_in).reshape(batch_size, T + padding, S)\n",
    "            out = out[..., :-padding, :]\n",
    "#             out = model(x).reshape(y.shape)\n",
    "            data_loss = myloss(out, y)\n",
    "\n",
    "            loss_u, f_loss = PINO_loss_Burgers(out, x[:, 0, :, 0], nu=nu)\n",
    "            test_err.append(data_loss.item())\n",
    "            f_err.append(f_loss.item())\n",
    "\n",
    "    mean_f_err = np.mean(f_err)\n",
    "    std_f_err = np.std(f_err, ddof=1) / np.sqrt(len(f_err))\n",
    "\n",
    "    mean_err = np.mean(test_err)\n",
    "    std_err = np.std(test_err, ddof=1) / np.sqrt(len(test_err))\n",
    "\n",
    "    print(f'==Averaged relative L2 error mean: {mean_err}, std error: {std_err}==\\n'\n",
    "          f'==Averaged equation error mean: {mean_f_err}, std error: {std_f_err}==')\n",
    "            \n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file = 'configs/custom/burgers-0003.yaml'\n",
    "config = load_config(config_file)\n",
    "display(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nsamples = config['data']['total_num']\n",
    "N = config['data']['nx']\n",
    "Nt0 = config['data']['nt']\n",
    "nu = config['data']['nu']\n",
    "sub_x = config['data']['sub']\n",
    "sub_t = config['data']['sub_t']\n",
    "Nx = N // sub_x\n",
    "Nt = Nt0 // sub_t + 1\n",
    "dim = 1\n",
    "l = 0.1\n",
    "L = 1.0\n",
    "sigma = 0.5 #2.0\n",
    "Nu = None # 2.0\n",
    "dt = 1.0e-4\n",
    "tend = 1.0\n",
    "save_int = int(tend/dt/Nt)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grf = GRF_Mattern(dim, N, length=L, nu=Nu, l=l, sigma=sigma, boundary=\"periodic\", device=device)\n",
    "U0 = grf.sample(Nsamples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "U0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "burgers_eq = BurgersEq1D(Nx=Nx, nu=nu, dt=dt, device=device)\n",
    "save_interval = int(1e-2/dt)\n",
    "U = vmap(burgers_eq.burgers_driver, in_dims=(0, None))(U0, save_interval) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = U0.cpu().float()\n",
    "u = U.cpu().float()\n",
    "display(u.shape,a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DataLoader1D(a, u, config['data']['nx'], config['data']['nt'])\n",
    "train_loader = dataset.make_loader(config['data']['n_train'], config['train']['batchsize'], start=0, train=True)\n",
    "test_loader = dataset.make_loader(config['data']['n_test'], config['test']['batchsize'], start=config['data']['n_train'], train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FNN2d(modes1=config['model']['modes1'],\n",
    "              modes2=config['model']['modes2'],\n",
    "              fc_dim=config['model']['fc_dim'],\n",
    "              layers=config['model']['layers'],\n",
    "              activation=config['model']['activation'],\n",
    "             ).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = FNN2d_AD(modes1=config['model']['modes1'],\n",
    "#                   modes2=config['model']['modes2'],\n",
    "#                   fc_dim=config['model']['fc_dim'],\n",
    "#                   layers=config['model']['layers'],\n",
    "#                   activation=config['model']['activation']).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log = False\n",
    "\n",
    "optimizer = Adam(model.parameters(), betas=(0.9, 0.999),lr=config['train']['base_lr'])\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer,\n",
    "                                                 milestones=config['train']['milestones'],\n",
    "                                                 gamma=config['train']['scheduler_gamma'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load from checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load_checkpoint(model, ckpt_path=config['train']['ckpt'], optimizer=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_Burgers(model,\n",
    "              train_loader,\n",
    "              optimizer,\n",
    "              scheduler,\n",
    "              config,\n",
    "              rank=0,\n",
    "              log=log,\n",
    "              project=config['log']['project'],\n",
    "              group=config['log']['group'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_Burgers_padding(model,\n",
    "              train_loader,\n",
    "              optimizer,\n",
    "              scheduler,\n",
    "              config,\n",
    "              padding=5,\n",
    "              rank=0,\n",
    "              log=log,\n",
    "              project=config['log']['project'],\n",
    "              group=config['log']['group'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_Burgers(model, test_loader, config, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_Burgers_padding(model, test_loader, config=config, padding=5, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nx = config['data']['nx']\n",
    "Nt = config['data']['nt'] + 1\n",
    "N = config['data']['n_test']\n",
    "model.eval()\n",
    "test_x = np.zeros((N,Nt,Nx,3))\n",
    "preds_y = np.zeros((N,Nt,Nx))\n",
    "test_y = np.zeros((N,Nt,Nx))\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(test_loader):\n",
    "        data_x, data_y = data\n",
    "        data_x, data_y = data_x.to(device), data_y.to(device)\n",
    "        pred_y = model(data_x).reshape(data_y.shape)\n",
    "        test_x[i] = data_x.cpu().numpy()\n",
    "        test_y[i] = data_y.cpu().numpy()\n",
    "        preds_y[i] = pred_y.cpu().numpy()\n",
    "#     data_loss = myloss(out, y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Test Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unpadded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nx = config['data']['nx']\n",
    "Nt = config['data']['nt'] + 1\n",
    "N = config['data']['n_test']\n",
    "model.eval()\n",
    "test_x = np.zeros((N,Nt,Nx,3))\n",
    "preds_y = np.zeros((N,Nt,Nx))\n",
    "test_y = np.zeros((N,Nt,Nx))\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(test_loader):\n",
    "        data_x, data_y = data\n",
    "        data_x, data_y = data_x.to(device), data_y.to(device)\n",
    "        pred_y = model(data_x).reshape(data_y.shape)\n",
    "        test_x[i] = data_x.cpu().numpy()\n",
    "        test_y[i] = data_y.cpu().numpy()\n",
    "        preds_y[i] = pred_y.cpu().numpy()\n",
    "#     data_loss = myloss(out, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_train_data = False\n",
    "padding = 5\n",
    "batch_size = config['test']['batchsize']\n",
    "Nx = config['data']['nx']\n",
    "# Ny = config['data']['nx']\n",
    "Nt = config['data']['nt'] + 1\n",
    "Ntest = config['data']['n_test']\n",
    "Ntrain = config['data']['n_train']\n",
    "loader = test_loader\n",
    "if use_train_data:\n",
    "    Ntest = Ntrain\n",
    "    loader = train_loader\n",
    "# in_dim = config['model']['in_dim']\n",
    "# out_dim = config['model']['out_dim']\n",
    "\n",
    "model.eval()\n",
    "# model.to('cpu')\n",
    "test_x = np.zeros((Ntest,Nt,Nx,3))\n",
    "preds_y = np.zeros((Ntest,Nt,Nx))\n",
    "test_y = np.zeros((Ntest,Nt,Nx))\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(loader):\n",
    "#     for i, data in enumerate(train_loader):\n",
    "        data_x, data_y = data\n",
    "        data_x, data_y = data_x.to(device), data_y.to(device)\n",
    "#         data_x_pad = F.pad()\n",
    "#         display(data_x.shape)\n",
    "        data_x_pad = F.pad(data_x, (0, 0, 0, 0, 0, padding), \"constant\", 0)\n",
    "        pred_y_pad = model(data_x_pad).reshape(batch_size, Nt + padding, Nx)\n",
    "#         out = out[..., :-padding, :]\n",
    "#         pred_y_pad = model(data_x_pad).reshape(batch_size, Nx, Ny, Nt + padding, out_dim)\n",
    "        pred_y = pred_y_pad[..., :-padding, :].reshape(data_y.shape)\n",
    "#         pred_y = model(data_x).reshape(data_y.shape)\n",
    "        test_x[i] = data_x.cpu().numpy()\n",
    "        test_y[i] = data_y.cpu().numpy()\n",
    "#         test_y0[i] = data_x[..., 0, -out_dim:].cpu().numpy() # same way as in training code\n",
    "        preds_y[i] = pred_y.cpu().numpy()\n",
    "#     data_loss = myloss(out, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(preds_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = 0\n",
    "pred = preds_y[key]\n",
    "true = test_y[key]\n",
    "\n",
    "\n",
    "a = test_x[key]\n",
    "Nt, Nx, _ = a.shape\n",
    "u0 = a[0,:,0]\n",
    "T = a[:,:,2]\n",
    "X = a[:,:,1]\n",
    "x = X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(24,5))\n",
    "plt.subplot(1,4,1)\n",
    "\n",
    "plt.plot(x, u0)\n",
    "plt.xlabel('$x$')\n",
    "plt.ylabel('$u$')\n",
    "plt.title('Intial Condition $u(x)$')\n",
    "plt.xlim([0,1])\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.subplot(1,4,2)\n",
    "# plt.pcolor(XX,TT, S_test, cmap='jet')\n",
    "plt.pcolormesh(X, T, true, cmap='jet', shading='gouraud')\n",
    "plt.colorbar()\n",
    "plt.xlabel('$x$')\n",
    "plt.ylabel('$t$')\n",
    "plt.title(f'Exact $s(x,t)$')\n",
    "plt.tight_layout()\n",
    "plt.axis('square')\n",
    "\n",
    "plt.subplot(1,4,3)\n",
    "# plt.pcolor(XX,TT, S_pred, cmap='jet')\n",
    "plt.pcolormesh(X, T, pred, cmap='jet', shading='gouraud')\n",
    "plt.colorbar()\n",
    "plt.xlabel('$x$')\n",
    "plt.ylabel('$t$')\n",
    "plt.title(f'Predict $s(x,t)$')\n",
    "plt.axis('square')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.subplot(1,4,4)\n",
    "# plt.pcolor(XX,TT, S_pred - S_test, cmap='jet')\n",
    "plt.pcolormesh(X, T, pred - true, cmap='jet', shading='gouraud')\n",
    "plt.colorbar()\n",
    "plt.xlabel('$x$')\n",
    "plt.ylabel('$t$')\n",
    "plt.title('Absolute error')\n",
    "plt.tight_layout()\n",
    "plt.axis('square')\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save and Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_data(data_path, test_x, test_y, preds_y):\n",
    "    data_dir, data_filename = os.path.split(data_path)\n",
    "    os.makedirs(data_dir, exist_ok=True)\n",
    "    np.savez(data_path, test_x=test_x, test_y=test_y, preds_y=preds_y)\n",
    "\n",
    "def load_data(data_path):\n",
    "    data = np.load(data_path)\n",
    "    test_x = data['test_x']\n",
    "    test_y = data['test_y']\n",
    "    preds_y = data['preds_y']\n",
    "    return test_x, test_y, preds_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'data/Burgers1D'\n",
    "data_filename = 'data.npz'\n",
    "data_path = os.path.join(data_dir, data_filename)\n",
    "# os.makedirs(data_dir, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_data(data_path, test_x, test_y, preds_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x, test_y, preds_y = load_data(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_predictions(key, test_x, test_y, preds_y, print_index=False, save_path=None, font_size=None):\n",
    "    if font_size is not None:\n",
    "        plt.rcParams.update({'font.size': font_size})\n",
    "    pred = preds_y[key]\n",
    "    true = test_y[key]\n",
    "\n",
    "\n",
    "    a = test_x[key]\n",
    "    Nt, Nx, _ = a.shape\n",
    "    u0 = a[0,:,0]\n",
    "    T = a[:,:,2]\n",
    "    X = a[:,:,1]\n",
    "    x = X[0]\n",
    "\n",
    "    # Plot\n",
    "    fig = plt.figure(figsize=(23,5))\n",
    "    plt.subplot(1,4,1)\n",
    "\n",
    "    plt.plot(x, u0)\n",
    "    plt.xlabel('$x$')\n",
    "    plt.ylabel('$u$')\n",
    "    plt.title('Intial Condition $u(x)$')\n",
    "    plt.xlim([0,1])\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.subplot(1,4,2)\n",
    "    # plt.pcolor(XX,TT, S_test, cmap='jet')\n",
    "    plt.pcolormesh(X, T, true, cmap='jet', shading='gouraud')\n",
    "    plt.colorbar()\n",
    "    plt.xlabel('$x$')\n",
    "    plt.ylabel('$t$')\n",
    "    plt.title(f'Exact $u(x,t)$')\n",
    "    plt.tight_layout()\n",
    "    plt.axis('square')\n",
    "\n",
    "    plt.subplot(1,4,3)\n",
    "    # plt.pcolor(XX,TT, S_pred, cmap='jet')\n",
    "    plt.pcolormesh(X, T, pred, cmap='jet', shading='gouraud')\n",
    "    plt.colorbar()\n",
    "    plt.xlabel('$x$')\n",
    "    plt.ylabel('$t$')\n",
    "    plt.title(f'Predict $u(x,t)$')\n",
    "    plt.axis('square')\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.subplot(1,4,4)\n",
    "    # plt.pcolor(XX,TT, S_pred - S_test, cmap='jet')\n",
    "    plt.pcolormesh(X, T, pred - true, cmap='jet', shading='gouraud')\n",
    "    plt.colorbar()\n",
    "    plt.xlabel('$x$')\n",
    "    plt.ylabel('$t$')\n",
    "    plt.title('Absolute Error')\n",
    "    plt.tight_layout()\n",
    "    plt.axis('square')\n",
    "\n",
    "    if save_path is not None:\n",
    "        plt.savefig(f'{save_path}.png', bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "figures_dir = 'Burgers1D/figures/'\n",
    "os.makedirs(figures_dir, exist_ok=True)\n",
    "font_size = 12\n",
    "for key in range(len(preds_y)):\n",
    "    save_path = os.path.join(figures_dir, f'Burgers1D_{key}')\n",
    "    plot_predictions(key, test_x, test_y, preds_y, print_index=True, save_path=save_path, font_size=font_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_movie_1D(key, test_x, test_y, preds_y, plot_title='', movie_dir='', movie_name='movie.gif', frame_basename='movie', frame_ext='jpg', remove_frames=True, font_size=None):\n",
    "    frame_files = []\n",
    "    os.makedirs(movie_dir, exist_ok=True)\n",
    "\n",
    "    if font_size is not None:\n",
    "        plt.rcParams.update({'font.size': font_size})\n",
    "    \n",
    "    pred = preds_y[key]\n",
    "    true = test_y[key]\n",
    "\n",
    "    \n",
    "    a = test_x[key]\n",
    "    Nt, Nx, _ = a.shape\n",
    "    u0 = a[0,:,0]\n",
    "    T = a[:,:,2]\n",
    "    X = a[:,:,1]\n",
    "    x = X[0]\n",
    "    t = T[:,0]\n",
    "\n",
    "    fig = plt.figure(figsize=(6,5))\n",
    "    ax = fig.add_subplot(111)\n",
    "    plt.ion()\n",
    "\n",
    "    fig.show()\n",
    "    fig.canvas.draw()\n",
    "    a = test_x[key]\n",
    "    Nt, Nx, _ = a.shape\n",
    "    u0 = a[0,:,0]\n",
    "    T = a[:,:,2]\n",
    "    X = a[:,:,1]\n",
    "    x = X[0]\n",
    "    ax.plot(x, true[0], 'b-', label='Exact')\n",
    "    ax.plot(x, pred[0], 'r--', label='PINO Prediction')\n",
    "    ylim = plt.ylim()\n",
    "    xlim = [0, 1]\n",
    "#     plt.xlim(xlim)\n",
    "#     plt.xlabel(f'$x$')\n",
    "#     plt.ylabel(f'$u$')\n",
    "#     plt.title(f'{plot_title} $t={t[0]:.2f}$')\n",
    "#     plt.legend(loc='lower right')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    \n",
    "    \n",
    "    for i in range(Nt):\n",
    "        ax.clear()\n",
    "        ax.plot(x, true[i], 'b-', label='Exact')\n",
    "        ax.plot(x, pred[i], 'r--', label='PINO Prediction')\n",
    "        plt.ylim(ylim)\n",
    "        plt.xlim(xlim)\n",
    "        plt.xlabel(f'$x$')\n",
    "        plt.ylabel(f'$u$')\n",
    "        plt.title(f'{plot_title} $t={t[i]:.2f}$')\n",
    "        plt.legend(loc='lower right')\n",
    "        plt.tight_layout()\n",
    "        fig.canvas.draw()\n",
    "#         plt.show()\n",
    "        if movie_dir:\n",
    "            frame_path = os.path.join(movie_dir,f'{frame_basename}-{i:03}.{frame_ext}')\n",
    "            frame_files.append(frame_path)\n",
    "            plt.savefig(frame_path)\n",
    "    \n",
    "    if movie_dir:\n",
    "        movie_path = os.path.join(movie_dir, movie_name)\n",
    "        with imageio.get_writer(movie_path, mode='I') as writer:\n",
    "            for frame in frame_files:\n",
    "                image = imageio.imread(frame)\n",
    "                writer.append_data(image)\n",
    "                \n",
    "    if movie_dir and remove_frames:\n",
    "        for frame in frame_files:\n",
    "            try:\n",
    "                os.remove(frame)\n",
    "            except:\n",
    "                pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Movie Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'data/Burgers1D'\n",
    "data_filename = 'data.npz'\n",
    "data_path = os.path.join(data_dir, data_filename)\n",
    "test_x, test_y, preds_y = load_data(data_path)\n",
    "movie_dir = f'Burgers1D/movie/'\n",
    "os.makedirs(movie_dir, exist_ok=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Movie 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "key = 0\n",
    "movie_name = f'Burgers1D_{key}.gif'\n",
    "frame_basename = f'Burgers1D_{key}_frame'\n",
    "frame_ext = 'jpg'\n",
    "plot_title = \"Burgers Equation\"\n",
    "font_size = 12\n",
    "remove_frames = True\n",
    "\n",
    "generate_movie_1D(key, test_x, test_y, preds_y, plot_title=plot_title, movie_dir=movie_dir, movie_name=movie_name, frame_basename=frame_basename, frame_ext=frame_ext, remove_frames=remove_frames, font_size=font_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Movie 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "key = 1\n",
    "movie_name = f'Burgers1D_{key}.gif'\n",
    "frame_basename = f'Burgers1D_{key}_frame'\n",
    "frame_ext = 'jpg'\n",
    "plot_title = \"Burgers Equation\"\n",
    "font_size = 12\n",
    "remove_frames = True\n",
    "\n",
    "generate_movie_1D(key, test_x, test_y, preds_y, plot_title=plot_title, movie_dir=movie_dir, movie_name=movie_name, frame_basename=frame_basename, frame_ext=frame_ext, remove_frames=remove_frames, font_size=font_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Movie 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "key = 2\n",
    "movie_name = f'Burgers1D_{key}.gif'\n",
    "frame_basename = f'Burgers1D_{key}_frame'\n",
    "frame_ext = 'jpg'\n",
    "plot_title = \"Burgers Equation\"\n",
    "font_size = 12\n",
    "remove_frames = True\n",
    "\n",
    "generate_movie_1D(key, test_x, test_y, preds_y, plot_title=plot_title, movie_dir=movie_dir, movie_name=movie_name, frame_basename=frame_basename, frame_ext=frame_ext, remove_frames=remove_frames, font_size=font_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "pred = preds_y[key]\n",
    "true = test_y[key]\n",
    "a = test_x[key]\n",
    "Nt, Nx, _ = a.shape\n",
    "u0 = a[0,:,0]\n",
    "T = a[:,:,2]\n",
    "X = a[:,:,1]\n",
    "x = X[0]\n",
    "fig = plt.figure(figsize=(6,5))\n",
    "ax = fig.add_subplot(111)\n",
    "plt.ion()\n",
    "fig.show()\n",
    "fig.canvas.draw()\n",
    "a = test_x[key]\n",
    "Nt, Nx, _ = a.shape\n",
    "u0 = a[0,:,0]\n",
    "T = a[:,:,2]\n",
    "X = a[:,:,1]\n",
    "x = X[0]\n",
    "ax.plot(x, true[0], 'b-', label='Exact')\n",
    "ax.plot(x, pred[0], 'r--', label='PINO Prediction')\n",
    "ylim = plt.ylim()\n",
    "xlim = [0, 1]\n",
    "plt.xlim(xlim)\n",
    "plt.xlabel(f'$x$')\n",
    "plt.ylabel(f'$u$')\n",
    "plt.title(f'Burgers Equation $t={t[0]:.2f}$')\n",
    "plt.legend(loc='lower right')\n",
    "plt.tight_layout()\n",
    "for i in range(Nt):\n",
    "    ax.clear()\n",
    "    ax.plot(x, true[i], 'b-', label='Exact')\n",
    "    ax.plot(x, pred[i], 'r--', label='PINO Prediction')\n",
    "    plt.ylim(ylim)\n",
    "    plt.xlim(xlim)\n",
    "    plt.xlabel(f'$x$')\n",
    "    plt.ylabel(f'$u$')\n",
    "    plt.title(f'Burgers Equation $t={t[i]:.2f}$')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.tight_layout()\n",
    "    fig.canvas.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = 0\n",
    "a = test_x[key]\n",
    "\n",
    "Nt, Nx, _ = a.shape\n",
    "u0 = a[0,:,0]\n",
    "T = a[:,:,2]\n",
    "X = a[:,:,1]\n",
    "x = X[0]\n",
    "t = T[:,0]\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "fig = plt.figure(figsize=(6,5))\n",
    "ax = fig.add_subplot(111)\n",
    "plt.ion()\n",
    "\n",
    "fig.show()\n",
    "fig.canvas.draw()\n",
    "a = test_x[key]\n",
    "Nt, Nx, _ = a.shape\n",
    "u0 = a[0,:,0]\n",
    "T = a[:,:,2]\n",
    "X = a[:,:,1]\n",
    "x = X[0]\n",
    "t = T[:,0]\n",
    "ax.plot(x, true[0], 'b-', label='Exact')\n",
    "ax.plot(x, pred[0], 'r--', label='PINO Prediction')\n",
    "ylim = plt.ylim()\n",
    "xlim = [0, 1]\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "\n",
    "for i in range(Nt):\n",
    "    ax.clear()\n",
    "    ax.plot(x, true[i], 'b-', label='Exact')\n",
    "    ax.plot(x, pred[i], 'r--', label='PINO Prediction')\n",
    "    plt.ylim(ylim)\n",
    "    plt.xlim(xlim)\n",
    "    plt.xlabel(f'$x$')\n",
    "    plt.ylabel(f'$u$')\n",
    "    plt.title(f'Burgers Equation $t={t[i]:.2f}$')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.tight_layout()\n",
    "    fig.canvas.draw()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
